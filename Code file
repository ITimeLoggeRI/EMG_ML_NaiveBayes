# Gerekli kütüphaneleri içe aktar
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, log_loss
from sklearn.preprocessing import LabelEncoder, StandardScaler
import joblib
import json
import io

# Colab için dosya yükleme
from google.colab import files
uploaded = files.upload()  # Dosya yükleme ekranı açılır

# Yüklenen dosyayı pandas ile oku
file_name = list(uploaded.keys())[0]
df = pd.read_csv(io.BytesIO(uploaded[file_name]), encoding='ISO-8859-9', delimiter=';')

# Hot Deck Imputation fonksiyonu
def hot_deck_impute(df):
    for column in df.columns:
        missing = df[column].isnull()
        if missing.any():
            df.loc[missing, column] = df[column].dropna().sample(n=missing.sum(), random_state=42).values
    return df

# Eksik değerleri doldurmak için Hot Deck Imputation uygula
X = df.drop('Ana el', axis=1)  # Bağımsız değişkenler
y = df['Ana el']  # Hedef değişken

# Virgülleri noktalarla değiştir ve sayısal değerlere dönüştür
X = X.applymap(lambda x: str(x).replace(',', '.') if isinstance(x, str) else x)
X = X.astype(float)
X = hot_deck_impute(X)

# Hedef değişkeni sayısal değerlere dönüştür
y = y.astype(str)
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Veriyi eğitim ve test setlerine böl
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# Özellik ölçeklendirme (isteğe bağlı)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Naive Bayes modeli oluştur ve eğit
model = GaussianNB()
model.fit(X_train_scaled, y_train)

# Eğitim ve test setlerinde tahmin yap
y_train_pred_proba = model.predict_proba(X_train_scaled)  # Eğitim verisi için olasılık tahminleri
y_test_pred_proba = model.predict_proba(X_test_scaled)    # Test verisi için olasılık tahminleri

# Cost fonksiyonlarını hesapla
train_cost = log_loss(y_train, y_train_pred_proba)
test_cost = log_loss(y_test, y_test_pred_proba)

print("\nTrain Cost (Log-Loss):", train_cost)
print("Test Cost (Log-Loss):", test_cost)

# Test setinde sınıf tahminleri
y_pred = model.predict(X_test_scaled)

# Performans ölçümleri
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Modeli ve performans sonuçlarını kaydet
joblib.dump(model, "naive_bayes_model.pkl")

performance = {
    "Confusion Matrix": confusion_matrix(y_test, y_pred).tolist(),
    "Classification Report": classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True),
    "Train Cost (Log-Loss)": train_cost,
    "Test Cost (Log-Loss)": test_cost
}

with open("naive_bayes_performance.json", "w") as f:
    json.dump(performance, f, indent=4)

print("\nModel ve performans sonuçları kaydedildi.")
